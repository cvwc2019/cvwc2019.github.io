<!DOCTYPE html>
<html>
 <head>
 <meta http-equiv="Content-Type" content="text/html; charset="utf-8"/>
 <meta name="viewport" content="width=device-width, initial-scale=1.0">
 <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
	 
 <title>Program-CVWC2019</title>
 <link rel="stylesheet" type="text/css" href="./bootstrap.min.css">
 <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Lato:300,400|Roboto+Slab:400,700|Roboto:300,300i,400,400i,500,500i,700,700i">
 <link rel="stylesheet" type="text/css" href="./main.css" media="screen,projection">
 <link rel="icon" href="./icon.png" size="32x32">
 </head>
<body>

<div class="navbar navbar-default navbar-fixed-top">
 <div class="container">

 <div class="navbar-header">
 </div>

 <div class="navbar-collapse collapse" id="navbar-main">
 <ul class="nav navbar-nav">
 <li><a href="./index.html#body-home">Home</a></li>
 <li><a href="./challenge.html">Challenge</a></li>
 <li><a href="./cfp.html">Call for Papers</a></li>
 <li><a href="./people.html">People</a></li>
 <li><a href="./leaderboard.html">LeaderBoard</a></li>
 <li><a href="./program.html">Program</a></li>
 </ul>
 </div>

 </div>
</div>

<div class="container">
<div class="page-content">
<br>

<div class="row">
 <div class="col-xs-12">
 <h3>Preliminary Program</h3>
<table width="100%", borders="0",  style="border-collapse:separate; border-spacing:0px 10px;">
	<col align="left" />
  	<col align="left" />
	<tr>
		<td>&emsp;8:50-9:00</td> <td>Opening remark</td>
	</tr>
	<tr>
		<td>&emsp;9:00-9:30</td> <td>Invited talks 1 (30min with QA)</td>
	</tr>	
	<tr>
		<td>&emsp;9:30-10:00</td> <td>Invited talks 2</td>
	</tr>
	<tr>
		<td>&emsp;10:00-10:15</td> <td>Oral-1: paper #1 (15min with QA)</td>
	</tr>	
	<tr>
		<td>&emsp;10:15-11:00</td> <td>Morning break</td>
	</tr>	
	<tr>
		<td>&emsp;11:00-11:15</td> <td>Oral-2: paper #3</td>
	</tr>	
	<tr>
		<td>&emsp;11:15-11:30</td> <td>Oral-3: paper #4</td>
	</tr>	
	<tr>
		<td>&emsp;11:30-11:45</td> <td>Oral-4: paper #13</td>
	</tr>	
	<tr>
		<td>&emsp;11:45-12:00</td> <td>Oral-5: paper #15</td>
	</tr>
	<tr>
		<td>&emsp;12:00-13:30 </td> <td>Lunch break</td>
	</tr>
	<tr>
		<td>&emsp;13:30-14:00</td> <td>Invited talks 3</td>
	</tr>
	<tr>
		<td>&emsp;14:00-14:25</td> <td>Challenge Overview and Awards</td>
	</tr>
	<tr>
		<td>&emsp;14:25-14:40</td> <td>Track-1 winner talk: paper #21</td>
	</tr>
	<tr>
		<td>&emsp;14:40-15:00</td> <td>Track-3&4 winner talk (same team): paper #23</td>
	</tr>	
	<tr>
		<td>&emsp;15:00-16:30</td> <td>Breaks and poster session (all papers have poster)</td>
	</tr>
	<tr>
		<td>&emsp;16:30-17:00</td> <td>Invited talks 4</td>
	</tr>
	<tr>
		<td>&emsp;17:00-17:30</td> <td>Panel discussion</td>
	</tr>
	<tr>
		<td>&emsp;17:30-17:35</td> <td>Close remarks</td>
	</tr>								
</table>	
 </div>
</div>
</br>

<div class="row">
 <div class="col-xs-12">
 <h3>Accept Paper List</h3>
 </div>
</div>	
<div class="row">
 <div class="col-xs-12">
 Contributed Paper Track
 </div>
</div>
<div class="row">
 <div class="col-xs-12">
 <ul>
 <li>#1: Count, Crop, Recognise: Fine-Grained Recognition in the Wild; <span style='color: #0000FF'>Oral</span> <br>
 Max Bain (University of Oxford)*; Arsha Nagrani (Oxford University); Andrew Zisserman (University of Oxford)
 </li>
 <li>#3: Geo-Aware Networks for Fine Grained Recognition; <span style='color: #0000FF'>Oral</span> <br>
 Grace Chu (Google)*; Brian Potetz (Google); Weijun Wang (Google); Andrew Howard (Google); Yang Song (Google); Fernando Brucher (Google); Thomas Leung (Google); Hartwig Adam (Google)
 </li>
 <li>#8: Great Ape Detection in Challenging Jungle Camera Trap Footage via Attention-Based Spatial and Temporal Feature Blending;<br>
 Xinyu Yang (University of Bristol)*; Majid Mirmehdi (University of Bristol); Tilo Burghardt (University of Bristol)
 </li>
 <li>#11: ELPephants: A Fine-Grained Dataset for Elephant Re-Identification;<br>
 Matthias K&ouml;rschens (Friedrich Schiller University Jena)*
 </li>
 <li>#12: DeepBees &ndash; Building and Scaling Convolutional Neuronal Nets For Fast and Large-scale Visual Monitoring of Bee Hives;<br>
 Julian Ulrich Marstaller (Karlsruhe Institute of Technology (KIT))*; Simon Stock (KIT); Frederic Tausch (KIT)
 </li>
 <li>#17: Learning Deep Features for Giant Panda Gender Classification using Face Images;<br>
 Hongnian Wang (Sichuan Normal University, SICNU); Han Su (SICNU)*; Wai-Kin Adams Kong (Nanyang Technological University); Peng Chen (Chengdu Research Base of Giant Panda Breeding); Rong Hou (Chengdu Research Base of Giant Panda Breeding); Zhihe Zhang (Chengdu Research Base of Giant Panda Breeding); Weiyi Xie (SICNU)
 </li>
 </ul>
 </div>
</div>

<div class="row">
 <div class="col-xs-12">
 Challenge Solution Track
 </div>
</div>
<div class="row">
 <div class="col-xs-12">
 <ul>
 <li>#7: Pose-Guided Complementary Features Learning for Amur Tiger Re-Identification;<br>
 Qijun Zhao (Sichuan University)*; Ning Liu (SiChuan University); Nan Zhang (SiChuan University); Xinhua Cheng (Sichuan University); Jianing Zhu (SiChuan University)
 </li>
 <li>#19: A Hybrid Approach for Tiger Re-Identification;<br>
 Ankita Shukla (IIIT Delhi)*; Connor Anderson (Brigham Young University); Gullal Cheema (IIIT Delhi); Pei Guo (Brigham Young University); Suguru Onda (Brigham Young University); Divyam Anshumaan (IIIT Delhi); Saket Anand (IIIT Delhi); Ryan Farrell (Brigham Young University)
 </li>
 <li>#20: Bag of Tricks and A Strong Baseline for Tiger Re-ID;<br>
 Jiwen Yu (Northwestern Polytechnical University, NWPU); Junnan Liu (NWPU); Zhizheng Yang (NWPU); Zhouyangzi Zhang (NWPU); yixin zhu (NWPU); Haibo Su (NWPU); Lu Yang (NWPU); BingLiang Jiao (NWPU); Peng Wang (NWPU)*
 </li>
 <li>#21: Fast and Efficient Object Detection Model for Real-Time Tiger Detection In The Wild; <span style='color: #0000FF'>Oral</span> <br>
 Orest Kupyn (Ukrainian Catholic University)*; Dzmitry Pranchuk (WANNABY)
 </li>
 <li>#23: Part-Pose Guided Amur Tiger Re-identification; <span style='color: #0000FF'>Oral</span> <br>
 Cen Liu (Ningbo University); Rong Zhang (Ningbo University); Lijun Guo (Ningbo University)*
 </li>
 </ul>
 </div>
</div>

<div class="row">
 <div class="col-xs-12">
 Peer Reviewed Track
 </div>
</div>
<div class="row">
 <div class="col-xs-12">
 <ul>
 <li>#4: <a href="https://arxiv.org/abs/1807.04975", target="blank">Recognition in Terra Incognita</a>, <b>ECCV 2018</b>; <span style='color: #0000FF'>Oral</span> <br>
 Sara M Beery (Caltech)*; Grant Van Horn (Caltech); Pietro Perona (Caltech)
 </li>
 <li>#6: <a href="https://arxiv.org/abs/1907.07319", target="blank">Half a Percent of Labels is Enough: Efficient Animal Detection in UAV Imagery using Deep CNNs and Active Learning</a>, <b>IEEE TGRS</b>;<br>
 Benjamin Kellenberger (Wageningen University and Research)*; Diego Marcos (Wageningen University); Sylvain Lobry (Wageningen University and Research); Devis Tuia (Wageningen University and Research)
 </li>
 <li>#10: <a href="https://arxiv.org/abs/1906.11898", target="blank">Crowdsourcing Insect Observations to Assess Demographic Shifts and Improve Classification</a>, <b>ICML 2019 Workshop "AI for Social Good"</b>;<br>
 L&eacute;onard Boussioux (Ecole Centrale Paris, MILA, MIT)*; Charles Guille-Escuret (U. Montreal, MILA); Tomas Giro-Larraz (Ecole CentraleSup&eacute;lec, EPFL); Baptiste Goujaud (MILA); Mehdi Cherti (Mines Paristech); Balaszs Kegl (ChaLearn)
 </li>
 <li>#13: <a href="https://arxiv.org/abs/1908.07201", target="blank">3D Safari: Learning to Estimate Zebra Pose, Shape, and Texture from Images "In the Wild"</a>, <b>ICCV 2019</b>; <span style='color: #0000FF'>Oral</span> <br>
 Silvia Zuffi (IMATI-CNR)*; Angjoo Kanazawa (UCBerkeley); Tanya Berger-Wolf (University of Illinois at Chicago); Michael J. Black (Max Planck Institute for Intelligent Systems)
 </li>
 <li>#15: <a href="https://arxiv.org/abs/1906.05272", target="blank">Presence-Only Geographical Priors for Fine-Grained Image Classification</a>, <b>ICCV 2019</b>;<span style='color: #0000FF'>Oral</span><br>
 Oisin Mac Aodha (Caltech)*; Elijah Cole (Caltech); Pietro Perona (Caltech)
 </li>
 </ul>
 </div>
</div>

<!--p>
<br>
<div class="row">
 <div class="col-xs-12">
	 <b>Notes:</b>
<ol> 
 <li>Presentation type (oral/poster) will be available when full program is ready.</li>
 <li>Only papers from contributed track and challenge track will be included in the ICCV 2019 workshop proceeding.</li>
</ol> 
 </div>
</div></p-->

<br><br>
</div>
</div>

</body>
</html>
